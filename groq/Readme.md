
***
# Chat Using Groq 
***
This uses Groq inference engines for faster response/ inference time from Gemma-7b-It model. The system uses a Web based loader with loads information from Websites, here it loads *chains* documentation from langchain documentation.

## chatgroq
![groq](https://github.com/kanishkaran/langchain-practice/blob/38f3868552c25c7f8601674a2594b610bfbc66d9/chatgroq.png)

## Context Retrieved From Web
![groq-context](https://github.com/kanishkaran/langchain-practice/blob/38f3868552c25c7f8601674a2594b610bfbc66d9/groq-context.png)

## response-time
![response-time](https://github.com/kanishkaran/langchain-practice/blob/38f3868552c25c7f8601674a2594b610bfbc66d9/response-time.png)

## web-loading
![web-loading](https://github.com/kanishkaran/langchain-practice/blob/38f3868552c25c7f8601674a2594b610bfbc66d9/web-loading.png)
